{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading the MNIST dataset...\n",
      "[INFO] training size (60000, 28, 28, 1)\n",
      "[INFO] test size (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Loading the MNIST dataset...\")\n",
    "(trainData, trainLabels), (testData, testLabels) = mnist.load_data()\n",
    "trainData = np.multiply(1./255, trainData)\n",
    "testData = np.multiply(1./255, testData)\n",
    "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
    "testLabels = np_utils.to_categorical(testLabels, 10)\n",
    "trainData = trainData[:, :, :, np.newaxis]\n",
    "testData = testData[:, :, :, np.newaxis]\n",
    "print('[INFO] training size {}'.format(trainData.shape))\n",
    "print('[INFO] test size {}'.format(testData.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original model\n",
    "model_full_precision = load_model('./models/LeNet5_original.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternary model\n",
    "model_ternary = load_model('./models/LeNet5_ternary.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternary model with scalar-tuning\n",
    "model_ternary_scalar = load_model('./models/LeNet5_ternary_scalar.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 397us/step\n",
      "[INFO] Full precision model accuracy is: 99.22%\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = model_full_precision.evaluate(\n",
    "        testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] Full precision model accuracy is: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 389us/step\n",
      "[INFO] Ternary weights model accuracy is: 98.70%\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = model_ternary.evaluate(\n",
    "        testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] Ternary weights model accuracy is: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 389us/step\n",
      "[INFO] Ternary scalar-tuning model accuracy is: 99.10%\n"
     ]
    }
   ],
   "source": [
    "(loss, accuracy) = model_ternary_scalar.evaluate(\n",
    "        testData, testLabels, batch_size=128, verbose=1)\n",
    "print(\"[INFO] Ternary scalar-tuning model accuracy is: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Weights Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  original weights\n",
    "weights_full_precision = model_full_precision.get_weights()\n",
    "# ternary weights\n",
    "weights_ternary = model_ternary.get_weights()\n",
    "# scalar-tuning weights\n",
    "weights_ternary_scalar = model_ternary_scalar.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07828661  0.07991946  0.03333475  0.12516291  0.07970043]\n",
      " [ 0.04642316 -0.01765191  0.03420295  0.09401795 -0.01672778]\n",
      " [ 0.04315952  0.01074686  0.073874    0.0927763   0.06956593]\n",
      " [-0.02776762 -0.10874511  0.03971153  0.05412877  0.06917713]\n",
      " [-0.15361701 -0.15454859 -0.13040234 -0.00376264 -0.06776509]]\n"
     ]
    }
   ],
   "source": [
    "print(weights_full_precision[0][:, :, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  0.  1.  1.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  1.  1.]\n",
      " [ 0. -1.  0.  1.  1.]\n",
      " [-1. -1. -1.  0. -1.]]\n"
     ]
    }
   ],
   "source": [
    "print(weights_ternary[0][:, :, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08166043  0.08166043  0.          0.08166043  0.08166043]\n",
      " [ 0.          0.          0.          0.08166043  0.        ]\n",
      " [ 0.          0.          0.08166043  0.08166043  0.08166043]\n",
      " [ 0.         -0.12301452  0.          0.08166043  0.08166043]\n",
      " [-0.12301452 -0.12301452 -0.12301452  0.         -0.12301452]]\n"
     ]
    }
   ],
   "source": [
    "print(weights_ternary_scalar[0][:, :, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01191805  0.00381361  0.00187092 -0.01358425  0.00168212  0.00929875\n",
      "  0.00508314  0.00097986 -0.00902778  0.00424224 -0.01501222  0.00823121\n",
      "  0.0305446   0.00609368  0.00457578  0.00307899  0.00067997  0.0003576\n",
      "  0.00522174  0.00142306  0.00158354  0.00296732  0.01257685 -0.01380011\n",
      " -0.01120229 -0.02553516 -0.01151572 -0.00151149  0.01593739  0.00877792\n",
      " -0.00499236  0.00272836]\n"
     ]
    }
   ],
   "source": [
    "# oringinal\n",
    "print(weights_full_precision[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0. -1.  0.  1.  0.  0. -1.  0. -1.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1. -1. -1. -1. -1.  0.  1.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# ternary\n",
    "print(weights_ternary[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01389772  0.          0.         -0.01423954  0.          0.01389772\n",
      "  0.          0.         -0.01423954  0.         -0.01423954  0.01389772\n",
      "  0.01389772  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.01389772 -0.01423954 -0.01423954\n",
      " -0.01423954 -0.01423954  0.          0.01389772  0.01389772  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# ternary with scalar-tuning\n",
    "print(weights_ternary_scalar[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Cosine similarity Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(a_, t_):\n",
    "    return np.dot(a_.reshape(1, -1), t_.reshape(-1, 1)) / (norm(a_) * norm(t_) + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between full precision weights and ternary weights is *0.9233752489089966*\n"
     ]
    }
   ],
   "source": [
    "cosine = inner(weights_full_precision[0][:, :, 0, 1], weights_ternary[0][:, :, 0, 1])\n",
    "print(\"The cosine similarity between full precision weights and ternary weights is *{}*\".format(cosine[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between full precision weights and ternary scalar-tuning weights is *0.9423828125*\n"
     ]
    }
   ],
   "source": [
    "cosine = inner(weights_full_precision[0][:, :, 0, 1], weights_ternary_scalar[0][:, :, 0, 1])\n",
    "print(\"The cosine similarity between full precision weights and ternary scalar-tuning weights is *{}*\".format(cosine[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Predicted: 2, Actual: 2\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(0, len(testLabels)), size=(10,)):\n",
    "    # Use the model to classify the digit\n",
    "    # Please try models:ã€€ model_full_precision, model_ternary, and model_ternary_scalar\n",
    "    probs = model_ternary.predict(testData[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "\n",
    "    # Convert the digit data to a color image\n",
    "    image = (testData[i] * 255).astype(\"uint8\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # The images are in 28x28 size. Much too small to see properly\n",
    "    # So, we resize them to 280x280 for viewing\n",
    "    image = cv2.resize(image, (280, 280), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Add the predicted value on to the image\n",
    "    cv2.putText(image, str(prediction[0]), (20, 40),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, 1.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Show the image and prediction\n",
    "    print(\"[INFO] Predicted: {}, Actual: {}\".format(\n",
    "        prediction[0], np.argmax(testLabels[i])))\n",
    "    cv2.imshow(\"Digit\", image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
